How do do diffuse lighting?

Parallelization scaling / consistency tests
new binary geometry format for storing facet body metadata
point-in-polyhedron optimization for stl body (https://wvannoordt.github.io/misc-math/unitary-cover.pdf), adapt using existing metadata
self-shadow check: draw tangent plane and check for light sources on the non-normal side?

Render a ball! Use to calibrate lighting

How to do lighting passses through transparent objects?

Metadata for scene object: I think this is where a huge amount of performance can be gained back.

Computing relevant bodies  should actually save some relevant metadata that can be used to revisit the computation later, I.e. what is the collision plane, what is the 
index of the collision face, etc.


scene-camera-object-bound-transform relationship?
Some fundamental points about this:
	A scene should take a ray as an input.
	Every ray defines a plane, and objects behind that plane cannot be seen.
	This can be extended to each dimension, not just the plane of the ray. Hence, bounding boxes are good!
	check as few objects as possible.
	Ray collision checks have multiple stages: first, the plane check stage (described above), (intermediate stage), then the bounding box (not for sphere, ellipsoid) and
		last-level checks (which both belong to the object).
	Ray tracing is recursive. On the most basic level, a ray enters into a function and a color comes out. there should be a limit on the depth (3?)
	refractions will probably need to compute the transmitting ray AND the exiting ray.
	Color influence decreases with ray depth (mirrors facing each other, exponential decay)
	
Is an interface / inherited class efficient? 

ANTIALIASING
	Antialiasing might have to be modularized so that each aspect of a scene performs antialiasing independently. a compute-chader stage could be applied as
	a global antialiasing. If each render also produces a map of distances to collisions, then shader stages can be applied later for general purposes too.
	Note also that this map may be generated a priori as an optimization, although some heavy hand calculations need to be carried out and throughly tested
	before that is possible
	
Parallel.For()
	This is not a good solution for speeding up rendering. This is akin to the "parfor" directive in matlab, where a compute pool is initialized and similar operations
	are performed on different datasets. Still searching for a good way to do more low-level parallelization... maybe just write this all in C++
	
Distance computation:
	This should probably be done in two stages: a rough pass that gets candidates based on overlap between intervals of maximal/minimal distance, then a fine pass that
	computes the distance exactly.
